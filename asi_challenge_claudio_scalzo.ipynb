{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASI Challenge Exercise\n",
    "### Naive Bayes Classification and Baysian Linear Regression on the MNIST and CIFAR10 datasets\n",
    "<i>Claudio SCALZO</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES IMPORT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as math\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew, probplot, multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datasets loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTORY DEFINITION\n",
    "mnistPath = \"./datasets/Fashion-MNIST/\"\n",
    "\n",
    "# FILEPATHS DEFINITION\n",
    "mnistTrainFile = mnistPath + \"fashion-mnist_train.csv\"\n",
    "mnistTestFile = mnistPath + \"fashion-mnist_test.csv\"\n",
    "\n",
    "# LOAD THE MNIST AND CIFAR TRAINSET AND DATASET\n",
    "mnistTrain = pd.read_csv(mnistTrainFile)\n",
    "mnistTest = pd.read_csv(mnistTestFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO LOAD A SINGLE TRAINFILE\n",
    "def loadImages(filename):\n",
    "    \n",
    "    # Load binary file\n",
    "    file = open(filename, \"rb\")\n",
    "    \n",
    "    # Unpickle\n",
    "    data = pickle.load(file, encoding=\"bytes\")\n",
    "    \n",
    "    # Get raw images and raw classes\n",
    "    rawImages = data[b'data']\n",
    "    rawClasses = data[b'labels']\n",
    "\n",
    "    # Make numpy arrays\n",
    "    imgs = np.array(rawImages, dtype=float) / 255.0\n",
    "    clss = np.array(rawClasses)\n",
    "    \n",
    "    # Reshape the images\n",
    "    imgs = imgs.reshape([-1, 3, 32, 32]).transpose([0, 2, 3, 1])\n",
    "    \n",
    "    return imgs, clss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTORY AND CONSTANTS DEFINITION\n",
    "cifarPath = \"./datasets/CIFAR-10/\"\n",
    "numTrainFiles = 5\n",
    "numImagesPerFile = 10000\n",
    "numImages = numImagesPerFile * numTrainFiles\n",
    "imageWidth = 32\n",
    "imageHeight = 32\n",
    "imageChannels = 3\n",
    "\n",
    "# ALLOCATIONS\n",
    "images = np.zeros(shape=[numImages, imageHeight, imageWidth, imageChannels], dtype=float)\n",
    "classes = np.zeros(shape=[numImages], dtype=int)\n",
    "\n",
    "# LOAD ALL THE TRAINFILES\n",
    "begin = 0\n",
    "for i in range(numTrainFiles):\n",
    "    \n",
    "    # Load the images and classes for the \"i\"th trainfile\n",
    "    images_batch, cls_batch = loadImages(filename = cifarPath + \"data_batch_\" + str(i + 1))\n",
    "\n",
    "    # Images in this batch\n",
    "    num_images = len(images_batch)\n",
    "\n",
    "    # Append to the general arrays\n",
    "    end = begin + num_images\n",
    "    images[begin:end, :] = images_batch\n",
    "    classes[begin:end] = cls_batch\n",
    "    begin = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL DIMENSIONS MEANING: [ImageNumber, HeightPixel, WidthPixel, Channel]\n",
    "# NEW DIMENSIONS MEANING: [ImageNumber, Pixel]\n",
    "\n",
    "# ALLOCATE ARRAYS\n",
    "imagesNew = np.zeros(shape=[numImages, imageHeight * imageWidth], dtype=float)\n",
    "imageTmp = np.zeros(shape=[imageHeight, imageWidth], dtype=float)\n",
    "\n",
    "# FOR EACH IMAGE\n",
    "for i in range(numImages):\n",
    "    \n",
    "    # CREATE A TEMPORARY BLACK & WHITE PICTURE\n",
    "    imageTmp[:,:] = 0.21 * images[i,:,:,0] + 0.72 * images[i,:,:,1] + 0.07 * images[i,:,:,2]\n",
    "    \n",
    "    # RAVEL THE PICTURE IN ONE ROW\n",
    "    imagesNew[i] = np.ravel(imageTmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel1014</th>\n",
       "      <th>pixel1015</th>\n",
       "      <th>pixel1016</th>\n",
       "      <th>pixel1017</th>\n",
       "      <th>pixel1018</th>\n",
       "      <th>pixel1019</th>\n",
       "      <th>pixel1020</th>\n",
       "      <th>pixel1021</th>\n",
       "      <th>pixel1022</th>\n",
       "      <th>pixel1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.240941</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.188510</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.301098</td>\n",
       "      <td>0.372235</td>\n",
       "      <td>0.437176</td>\n",
       "      <td>0.451961</td>\n",
       "      <td>0.477490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362549</td>\n",
       "      <td>0.370863</td>\n",
       "      <td>0.395961</td>\n",
       "      <td>0.360667</td>\n",
       "      <td>0.277569</td>\n",
       "      <td>0.320706</td>\n",
       "      <td>0.563843</td>\n",
       "      <td>0.735843</td>\n",
       "      <td>0.480588</td>\n",
       "      <td>0.380824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.677922</td>\n",
       "      <td>0.527922</td>\n",
       "      <td>0.406196</td>\n",
       "      <td>0.396353</td>\n",
       "      <td>0.510980</td>\n",
       "      <td>0.645765</td>\n",
       "      <td>0.735765</td>\n",
       "      <td>0.768863</td>\n",
       "      <td>0.600235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.180588</td>\n",
       "      <td>0.255098</td>\n",
       "      <td>0.355961</td>\n",
       "      <td>0.448078</td>\n",
       "      <td>0.505451</td>\n",
       "      <td>0.519686</td>\n",
       "      <td>0.531451</td>\n",
       "      <td>0.535098</td>\n",
       "      <td>0.532824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294353</td>\n",
       "      <td>0.313961</td>\n",
       "      <td>0.302196</td>\n",
       "      <td>0.259059</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.270824</td>\n",
       "      <td>0.303569</td>\n",
       "      <td>0.327020</td>\n",
       "      <td>0.327843</td>\n",
       "      <td>0.331765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.096392</td>\n",
       "      <td>0.131686</td>\n",
       "      <td>0.135608</td>\n",
       "      <td>0.145373</td>\n",
       "      <td>0.153216</td>\n",
       "      <td>0.143451</td>\n",
       "      <td>0.146549</td>\n",
       "      <td>0.087176</td>\n",
       "      <td>0.101059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319020</td>\n",
       "      <td>0.251647</td>\n",
       "      <td>0.315490</td>\n",
       "      <td>0.264118</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.226549</td>\n",
       "      <td>0.184863</td>\n",
       "      <td>0.220157</td>\n",
       "      <td>0.255451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.702588</td>\n",
       "      <td>0.694745</td>\n",
       "      <td>0.723843</td>\n",
       "      <td>0.753569</td>\n",
       "      <td>0.762314</td>\n",
       "      <td>0.756745</td>\n",
       "      <td>0.760863</td>\n",
       "      <td>0.754863</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344902</td>\n",
       "      <td>0.333216</td>\n",
       "      <td>0.322275</td>\n",
       "      <td>0.309686</td>\n",
       "      <td>0.309608</td>\n",
       "      <td>0.295569</td>\n",
       "      <td>0.291647</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>0.291647</td>\n",
       "      <td>0.299490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.406549</td>\n",
       "      <td>0.420863</td>\n",
       "      <td>0.510431</td>\n",
       "      <td>0.527961</td>\n",
       "      <td>0.609843</td>\n",
       "      <td>0.441804</td>\n",
       "      <td>0.204275</td>\n",
       "      <td>0.169961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127765</td>\n",
       "      <td>0.137176</td>\n",
       "      <td>0.150863</td>\n",
       "      <td>0.172588</td>\n",
       "      <td>0.204275</td>\n",
       "      <td>0.230745</td>\n",
       "      <td>0.251725</td>\n",
       "      <td>0.273255</td>\n",
       "      <td>0.291137</td>\n",
       "      <td>0.316039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.739765</td>\n",
       "      <td>0.498510</td>\n",
       "      <td>0.542784</td>\n",
       "      <td>0.583922</td>\n",
       "      <td>0.591961</td>\n",
       "      <td>0.634275</td>\n",
       "      <td>0.700235</td>\n",
       "      <td>0.750157</td>\n",
       "      <td>0.809804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>0.626314</td>\n",
       "      <td>0.519882</td>\n",
       "      <td>0.563922</td>\n",
       "      <td>0.551451</td>\n",
       "      <td>0.521176</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.463725</td>\n",
       "      <td>0.457608</td>\n",
       "      <td>0.592549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.132588</td>\n",
       "      <td>0.132784</td>\n",
       "      <td>0.164314</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>0.308824</td>\n",
       "      <td>0.176510</td>\n",
       "      <td>0.170314</td>\n",
       "      <td>0.226941</td>\n",
       "      <td>0.282196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487255</td>\n",
       "      <td>0.462078</td>\n",
       "      <td>0.555725</td>\n",
       "      <td>0.573137</td>\n",
       "      <td>0.536745</td>\n",
       "      <td>0.609608</td>\n",
       "      <td>0.620824</td>\n",
       "      <td>0.521333</td>\n",
       "      <td>0.513765</td>\n",
       "      <td>0.504824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.696745</td>\n",
       "      <td>0.687804</td>\n",
       "      <td>0.679137</td>\n",
       "      <td>0.683255</td>\n",
       "      <td>0.694392</td>\n",
       "      <td>0.705333</td>\n",
       "      <td>0.695020</td>\n",
       "      <td>0.664902</td>\n",
       "      <td>0.673020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812902</td>\n",
       "      <td>0.793373</td>\n",
       "      <td>0.766902</td>\n",
       "      <td>0.685451</td>\n",
       "      <td>0.405098</td>\n",
       "      <td>0.278314</td>\n",
       "      <td>0.309490</td>\n",
       "      <td>0.328275</td>\n",
       "      <td>0.329373</td>\n",
       "      <td>0.329647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.487725</td>\n",
       "      <td>0.400745</td>\n",
       "      <td>0.360902</td>\n",
       "      <td>0.386980</td>\n",
       "      <td>0.393176</td>\n",
       "      <td>0.533255</td>\n",
       "      <td>0.669686</td>\n",
       "      <td>0.666588</td>\n",
       "      <td>0.557333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418824</td>\n",
       "      <td>0.422196</td>\n",
       "      <td>0.429216</td>\n",
       "      <td>0.437333</td>\n",
       "      <td>0.443176</td>\n",
       "      <td>0.451569</td>\n",
       "      <td>0.459412</td>\n",
       "      <td>0.470627</td>\n",
       "      <td>0.468353</td>\n",
       "      <td>0.469725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    pixel0    pixel1    pixel2    pixel3    pixel4    pixel5  \\\n",
       "0      6  0.240941  0.177647  0.188510  0.220000  0.301098  0.372235   \n",
       "1      9  0.677922  0.527922  0.406196  0.396353  0.510980  0.645765   \n",
       "2      9  1.000000  0.992157  0.992157  0.992157  0.992157  0.992157   \n",
       "3      4  0.096392  0.131686  0.135608  0.145373  0.153216  0.143451   \n",
       "4      1  0.702588  0.694745  0.723843  0.753569  0.762314  0.756745   \n",
       "5      1  0.446667  0.406549  0.420863  0.510431  0.527961  0.609843   \n",
       "6      2  0.739765  0.498510  0.542784  0.583922  0.591961  0.634275   \n",
       "7      7  0.132588  0.132784  0.164314  0.305176  0.308824  0.176510   \n",
       "8      8  0.696745  0.687804  0.679137  0.683255  0.694392  0.705333   \n",
       "9      3  0.487725  0.400745  0.360902  0.386980  0.393176  0.533255   \n",
       "\n",
       "     pixel6    pixel7    pixel8    ...      pixel1014  pixel1015  pixel1016  \\\n",
       "0  0.437176  0.451961  0.477490    ...       0.362549   0.370863   0.395961   \n",
       "1  0.735765  0.768863  0.600235    ...       0.088745   0.180588   0.255098   \n",
       "2  0.992157  0.992157  0.992157    ...       0.294353   0.313961   0.302196   \n",
       "3  0.146549  0.087176  0.101059    ...       0.319020   0.251647   0.315490   \n",
       "4  0.760863  0.754863  0.753333    ...       0.344902   0.333216   0.322275   \n",
       "5  0.441804  0.204275  0.169961    ...       0.127765   0.137176   0.150863   \n",
       "6  0.700235  0.750157  0.809804    ...       0.729373   0.626314   0.519882   \n",
       "7  0.170314  0.226941  0.282196    ...       0.487255   0.462078   0.555725   \n",
       "8  0.695020  0.664902  0.673020    ...       0.812902   0.793373   0.766902   \n",
       "9  0.669686  0.666588  0.557333    ...       0.418824   0.422196   0.429216   \n",
       "\n",
       "   pixel1017  pixel1018  pixel1019  pixel1020  pixel1021  pixel1022  pixel1023  \n",
       "0   0.360667   0.277569   0.320706   0.563843   0.735843   0.480588   0.380824  \n",
       "1   0.355961   0.448078   0.505451   0.519686   0.531451   0.535098   0.532824  \n",
       "2   0.259059   0.247294   0.270824   0.303569   0.327020   0.327843   0.331765  \n",
       "3   0.264118   0.296667   0.294118   0.226549   0.184863   0.220157   0.255451  \n",
       "4   0.309686   0.309608   0.295569   0.291647   0.307333   0.291647   0.299490  \n",
       "5   0.172588   0.204275   0.230745   0.251725   0.273255   0.291137   0.316039  \n",
       "6   0.563922   0.551451   0.521176   0.536667   0.463725   0.457608   0.592549  \n",
       "7   0.573137   0.536745   0.609608   0.620824   0.521333   0.513765   0.504824  \n",
       "8   0.685451   0.405098   0.278314   0.309490   0.328275   0.329373   0.329647  \n",
       "9   0.437333   0.443176   0.451569   0.459412   0.470627   0.468353   0.469725  \n",
       "\n",
       "[10 rows x 1025 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD THE LABEL COLUMN\n",
    "images = np.concatenate((np.asmatrix(classes).T, imagesNew), axis=1)\n",
    "\n",
    "# CREATE THE DATAFRAME\n",
    "attributes = [(\"pixel\" + str(i)) for i in range(imageHeight*imageWidth)]\n",
    "cifarTrain = pd.DataFrame(images, columns=[\"label\"] + attributes)\n",
    "cifarTrain[\"label\"] = cifarTrain[\"label\"].astype(int)\n",
    "cifarTrain.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "The first step is to investigate data. It is a fundamental section, where we will learn about our data. Initially we show and plot really simple statistics: they are not really interesting but they are useful to introduce us, to understand what we are dealing with.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 60000\n",
      "Attributes: 784 (without considering the label)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>214</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "5      4       0       0       0       5       4       5       5       3   \n",
       "6      4       0       0       0       0       0       0       0       0   \n",
       "7      5       0       0       0       0       0       0       0       0   \n",
       "8      4       0       0       0       0       0       0       3       2   \n",
       "9      8       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "5       5    ...            7         8         7         4         3   \n",
       "6       0    ...           14         0         0         0         0   \n",
       "7       0    ...            0         0         0         0         0   \n",
       "8       0    ...            1         0         0         0         0   \n",
       "9       0    ...          203       214       166         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "5         7         5         0         0         0  \n",
       "6         0         0         0         0         0  \n",
       "7         0         0         0         0         0  \n",
       "8         0         0         0         0         0  \n",
       "9         0         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PRINT TO DESCRIBE THE TRAIN\n",
    "print(\"Number of rows:\", mnistTrain.shape[0])\n",
    "print(\"Attributes:\", mnistTrain.drop(columns=['label']).shape[1], \"(without considering the label)\")\n",
    "display(mnistTrain.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "The number of rows is <b>60000</b>, while the number of columns is <b>785</b> (784 attributes + 1 label). But what does they mean?<br>\n",
    "<br>\n",
    "<list>\n",
    "    <li>Each <b>row</b> represents a picture.</li>\n",
    "    <li>Each <b>column</b> represents a pixel.</li>\n",
    "    <li>So, the <b>value</b> of a row <i>\"r\"</i> in a given column <i>\"c\"</i> represents the brightness (from 0 to 255) of a given pixel <i>\"c\"</i> in a given picture <i>\"r\"</i>.</li>\n",
    "</list>\n",
    "<br>\n",
    "If training on a big (where big refers to the number of pictures) dataset represent an advantage, a big dimensionality like this (784 attributes) can represent an issue for the predictive model, generally known as \"curse of dimensionality\" (<a href=\"https://en.wikipedia.org/wiki/Curse_of_dimensionality\">source</a>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 10000\n",
      "Attributes: 784 (without considering the label)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>105</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>136</td>\n",
       "      <td>155</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "5      2       0       0       0       0       0      44     105      44   \n",
       "6      8       0       0       0       0       0       0       0       0   \n",
       "7      6       0       0       0       0       0       0       0       1   \n",
       "8      5       0       0       0       0       0       0       0       0   \n",
       "9      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       8    ...          103        87        56         0         0   \n",
       "1       0    ...           34         0         0         0         0   \n",
       "2      99    ...            0         0         0         0        63   \n",
       "3       0    ...          137       126       140         0       133   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "5      10    ...          105        64        30         0         0   \n",
       "6       0    ...            0         0         0         0         0   \n",
       "7       0    ...          174       136       155        31         0   \n",
       "8       0    ...            0         0         0         0         0   \n",
       "9       0    ...           57        70        28         0         2   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "5         0         0         0         0         0  \n",
       "6         0         0         0         0         0  \n",
       "7         1         0         0         0         0  \n",
       "8         0         0         0         0         0  \n",
       "9         0         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PRINT TO DESCRIBE THE TEST\n",
    "print(\"Number of rows:\", mnistTest.shape[0])\n",
    "print(\"Attributes:\", mnistTest.drop(columns=['label']).shape[1], \"(without considering the label)\")\n",
    "display(mnistTest.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data distribution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "Now is time to analyze the distribution of our data: let's do it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE DISTRIBUTION\n",
    "distribution = mnistTrain[\"label\"].value_counts()\n",
    "\n",
    "# TAKE NUMBERS AND FREQUENCIES\n",
    "numbers = np.array(distribution.index)\n",
    "frequencies = np.array(distribution.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT THE DISTRIBUTION OF THE TARGET VARIABLE\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(numbers, frequencies, align=\"center\", color=\"darkorange\")\n",
    "plt.xticks([i for i in range(np.min(numbers),np.max(numbers)+1)])\n",
    "plt.title(\"Distribution of the label\", weight=\"semibold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "The distribution is uniform! That can be a problem for our Naive Bayes implementation, expecting a Gaussian distribution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "Naive Bayes Classifier explanation here...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBC:\n",
    "    \n",
    "    # ----- PRIVATE METHODS ------------------------------------------------- #\n",
    "    # MEANS AND VARIANCES FOR THE LIKELIHOOD: P(X|C)\n",
    "    def _computeMeansCov(self):\n",
    "        \n",
    "        # Compute means and variances\n",
    "        # -> For example:\n",
    "        #    <means> |  attr0 | attr1 | ...    #  <vars> |  attr0 | attr1 | ...\n",
    "        #    --------------------------        # --------------------------    \n",
    "        #    class0  |   12   |   3   | ...    # class0  |   0.2  |  0.03 | ...\n",
    "        #    class1  |   8    |   0   | ...    # class1  |  0.07  |  0.1  | ...\n",
    "        #      ...   |  ...   |  ...  | ...    #   ...   |  ...   |  ...  | ...\n",
    "        self.means = self.train.groupby(\"label\").mean()\n",
    "        self.cov = self.train.groupby(\"label\").var()\n",
    "    \n",
    "    \n",
    "    # PRIORS: P(C)\n",
    "    def _computePriors(self):\n",
    "        \n",
    "        # Set a probability for each class: a dictionary of all P(Ci)\n",
    "        # -> For example: {class0: 0.01, class1: 0.27, ...}\n",
    "        self.priors = {k: v / self.nTrain for k, v in self.frequencies.items()}\n",
    "    \n",
    "    \n",
    "    # LIKELIHOOD: P(X|C)\n",
    "    def _logLikelihood(self, data, c):\n",
    "        \n",
    "        # Means and variances for class \"c\"\n",
    "        meansC = np.array(self.means.loc[c])\n",
    "        covC = np.array(self.means.loc[c])\n",
    "        \n",
    "        # Use the logarithmic pdf of the Multivariate Gaussian\n",
    "        return multivariate_normal.logpdf(data, meansC, covC + 1e-3)\n",
    "    # ----------------------------------------------------------------------- # \n",
    "    \n",
    "    \n",
    "    # ----- PUBLIC METHODS -------------------------------------------------- #\n",
    "    # TRAIN - LIKELIHOOD and PRIOR\n",
    "    def fit(self, train):\n",
    "        \n",
    "        # Trainset\n",
    "        self.train = train\n",
    "        self.nTrain, self.kTrain = train.shape\n",
    "        \n",
    "        # Compute the distribution of the label\n",
    "        self.frequencies = train[\"label\"].value_counts().to_dict()\n",
    "        \n",
    "        # Classes\n",
    "        self.classes = list(sorted(self.frequencies.keys()))\n",
    "        self.numC = len(self.classes)\n",
    "        \n",
    "        # Compute priors and likelihoods\n",
    "        self._computePriors()\n",
    "        self._computeMeansCov()\n",
    "    \n",
    "    \n",
    "    # TEST - POSTERIOR: P(C|X)\n",
    "    def predict(self, test):\n",
    "        \n",
    "        # Testset\n",
    "        self.nTest, self.kTest = test.shape\n",
    "        \n",
    "        # Init posterior array\n",
    "        # -> For example:\n",
    "        #     <post>  |  class0 | class1 | ...\n",
    "        #    -----------------------------\n",
    "        #    sample0  |   0.1   |  0.4   | ...\n",
    "        #    sample1  |   0.18  |  0.35  | ...\n",
    "        #      ...    |   ...   |  ...   | ...\n",
    "        posterior = np.zeros((self.nTest, self.numC))\n",
    "\n",
    "        # For each class\n",
    "        for c in self.classes:\n",
    "\n",
    "            # Compute posterior for class \"c\"\n",
    "            # -> posterior = likelihood * prior\n",
    "            #    or\n",
    "            # -> log(posterior) = log(likelihood) + log(prior)\n",
    "            posterior[:,c] = self._logLikelihood(test, c) + np.log(self.priors[c])\n",
    "\n",
    "        # Select the class with max probability for each sample\n",
    "        predictions = np.argmax(posterior, axis=1)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    # VALIDATE PREDICTION\n",
    "    def validate(self, pred, true):\n",
    "        \n",
    "        # Return the average number of different classes\n",
    "        return np.mean(pred != true)\n",
    "    # ----------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "MNIST dataset:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 1.727 seconds\n",
      "Test time: 4.851 seconds\n",
      "Error: 0.3622\n"
     ]
    }
   ],
   "source": [
    "# SPLIT IN TEST + TARGET\n",
    "true = mnistTest['label']\n",
    "train = mnistTrain\n",
    "test = mnistTest.drop(columns=['label'])\n",
    "\n",
    "# NAIVE BAYES CLASSIFIER\n",
    "nbc = NBC()\n",
    "\n",
    "# TRAIN\n",
    "startTime = time()\n",
    "nbc.fit(train)\n",
    "endTime = time()\n",
    "print(\"Train time: %.3f seconds\" % (endTime-startTime))\n",
    "\n",
    "# TEST\n",
    "startTime = time()\n",
    "pred = nbc.predict(test)\n",
    "endTime = time()\n",
    "print(\"Test time: %.3f seconds\" % (endTime-startTime))\n",
    "\n",
    "# ACCURACY (MSE)\n",
    "error = nbc.validate(pred, true)\n",
    "print(\"Error:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "Now it's time for the CIFAR10:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "Bayesian Linear Regression explanation here...\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
